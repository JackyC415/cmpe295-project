{"title":"Senior Data Engineer - Azure Data Factory - REMOTE NEW!","location":"","salary":"","description":"","term":"$50 to $60 HourlyContractor","detail":"https://www.ziprecruiter.com/k/l/AAJMzat5eGCon1DN-ZLCbOXryYBlRIcPDrulwKV6onVQPjpV6_wJ1DxrOLhCS0VZXH_lc-NcwEheMDALKYWek-wtYXI8NJ1KE1luy-duWTB36EifzLgQwNI9UGj4r3kSr3ht1d_mBEMd2EVJLvi13mKbFvhvREKQV3fFr02RQhjL5JfOWkyoy0ijhbZzcqqJ","source":"ziprecruiter","full_description":"Red Bridge is actively recruiting for a Senior Data Engineer. This is a 1 year remote contract position.Qualified Applicants must be legally authorized for employment in the Unites States. Qualified Applicants will not require employer sponsored work authorization now or in the future for employment in the United States.JOB SUMMARYThe Data Engineer will support software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.QUALIFICATIONSEducation: Bachelor’s degree in Computer Science or related fieldExperience: Eight years of experience in Information TechnologyTwo or more years of experience with at least one contemporary data transformation toolExpert knowledge of and strong experience with standard query language (SQL), Data Warehouse concepts and design.Must be able to build processes supporting data transformations, data structures, metadata, dependency and workload management.Expert knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores, and big data pipeline.Ability to read, understand, and develop various data structures.Must be able to explain and mentor junior team members in the above concepts and techniques.Ability to drive/travel to multiple facilities/locations as needed.Ability to be on-call and respond to production issues in a timely manner.Additional Skills/Requirements preferred:Understanding of Healthcare data is desired.Expert knowledge of and strong experience with ETL tools such as SSIS, Informatica, or Attunity Compose.Expert knowledge of and strong experience with data orchestration tools such as Control-M or ADF.Expert knowledge of and experience with two or more of ADLS, ADW, SQL PaaS, Azure Data Bricks, and NoSQL databases.ESSENTIAL FUNCTIONS1. Process: Extracts, tests, loads, and validates data. Analyze the data flow requirements and develops a scalable architecture for staging and loading data. Interprets the transformation rules for all target data objects and develops the software components to support the transformation. Assist with design/implementation of data staging methods. Prepare/implement data verification and testing methods. Create scripts/processes required to extract, transform, clean, and move data and metadata from a source application so they can be loaded into a data warehouse, data mart, or operational data store. Must be able to troubleshoot the existing code and develop new code, stored procedures, views, and functions.2. Documentation: Create and maintain ETL, data orchestration, and system documentation. Create source to target data lineage documentation. Maintain the development, test, user acceptance, and production ETL and data orchestration environments."}
{"title":"Software Engineer (ETL/Data)","location":"","salary":"","description":"","term":"Full-Time","detail":"https://www.ziprecruiter.com/k/l/AAJSApe8K1dNg2qWkBlp9OuWWk7NY65TkHCqVBaUlil8DC1gTF1M6Gm4nsJMiZRUKFX4AEgnp93gRZ4VEGuUgSLJBIu99BjI06ovYt8uP27hU0Eays7xVqUC7sohmTcNhCMNReD73QkULtI0oL1szcCHYwmORVF3pghcU0U2nlAbiwvi4Y0orjqvmKB_YeYi","source":"ziprecruiter","full_description":"Rx Savings Solutions has an opening for a ETL Software Engineer to join our rapidly growing team and fun-loving culture. The team at Rx Savings Solutions is driven to make a difference in the pharmaceutical industry by exposing cost-savings analytics to our members. We take pride knowing that the work we do can greatly impact the lives of our customers.We are looking for a passionate data engineer to develop a robust, scalable data model and optimize the consumption of data sources we require to generate unique insights about our systems. You will share in the ownership of the technical vision and direction for advanced analytics and insight products. You will work with top-notch technical professionals developing complex systems at scale and with a focus on sustained operational excellence. We are looking for people who are motivated by thinking big, moving fast, and exploring business insights. If you love to implement solutions to hard problems while working hard, having fun, and making history, this may be the opportunity for you.Position Qualifications:Basic Qualifications:Bachelor’s or Masters degree or greater in Computer Science , Computer Applications, Data Sciences, Computer Engineering or related experienceExperience with one or more query language (e.g., SQL, PL/SQL, DML, MDX, HiveQL, SparkSQL, )Experience with one or more scripting language (e.g., Python, R, Scala, C, C++,Shell(Bash or Korn))Experience with data mining, data warehouse solutions , FACT/DIMENSIONAL Modeling, Semantic Layers, Cube Design and ETL conceptsExperience with Columnar databases.Knowledge of several file formats – RDBMS, Parquet, AVRO,ACII, CSV,Knowledge of Structured and Unstructured dataKnowledge of Operating Systems – UNIX, LINUX,iOS,Android and WindowsKnowledge of Cloud Data WarehousingAware of AWS Services – S3, Lambda, Redshift, Cloudwatch, AWS GlueClear and concise communication skillsAbility to design and build pseudocode in SQL or programming language of choice.Job Requirements:Build data pipelines to Ingest and automate files provided by customers using Python , R, Scala or SQL in Spark environment (Databricks)Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using primarily SQL, Spark (Python/Scala) or any ETL tool (like Talend, Informatica, DataStage etc)Explore and learn the latest AWS technologies to provide new capabilities and increase efficiencyCollaborate with Business Intelligence Engineers to recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentationCollaborate with other data science team to implement advanced analytics algorithms that exploit our rich datasets for statistical analysis, prediction, clustering and machine learningHelp continually improve ongoing implementations and core portal processes, automating or simplifying self-service support for both internal and external customersPreferred Qualifications:ETL using Scala/PySpark /SqlSpark/R Spark or a tool (Talend, Informatica, DataStage, AWS Glue)Understanding of RDBMS, Data Warehouses, Cloud Data Warehousing, Cube Concepts, FACT/DIMENSIONAL Modeling, SQL best practices.If experienced in Talend, Must have worked on migrations from old version to newer versions (example : 6.4 to 7.2) and Must have experience in driving “lift &amp; Shift” Talend Migration efforts."}